C:\Users\user\anaconda3\python.exe D:/Detectron2_Custom_Dataset/train.py
[04/18 01:32:05 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
  )
)
WARNING [04/18 01:32:05 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[04/18 01:32:05 d2.data.datasets.coco]: Loaded 20 images in COCO format from train.json
[04/18 01:32:05 d2.data.build]: Removed 0 images with no usable annotations. 20 images left.
[04/18 01:32:05 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    kiwi    | 25           |
|            |              |
[04/18 01:32:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[04/18 01:32:05 d2.data.build]: Using training sampler TrainingSampler
[04/18 01:32:05 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...
[04/18 01:32:05 d2.data.common]: Serialized dataset takes 0.02 MiB
model_final_280758.pkl: 167MB [00:16, 10.3MB/s]                           
[04/18 01:32:23 d2.engine.train_loop]: Starting training from iteration 0
C:\Users\user\anaconda3\lib\site-packages\torch\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[04/18 01:38:42 d2.utils.events]:  eta: 5:15:25  iter: 19  total_loss: 0.5018  loss_cls: 0.4308  loss_box_reg: 0.06232  loss_rpn_cls: 0.003415  loss_rpn_loc: 0.002658  time: 18.9038  data_time: 0.2507  lr: 4.9953e-06  
[04/18 01:44:59 d2.utils.events]:  eta: 5:02:27  iter: 39  total_loss: 0.4712  loss_cls: 0.3835  loss_box_reg: 0.0565  loss_rpn_cls: 0.004953  loss_rpn_loc: 0.002553  time: 18.8797  data_time: 0.0022  lr: 9.9902e-06  
[04/18 01:51:14 d2.utils.events]:  eta: 4:57:38  iter: 59  total_loss: 0.3726  loss_cls: 0.3139  loss_box_reg: 0.04892  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.00185  time: 18.8236  data_time: 0.0021  lr: 1.4985e-05  
[04/18 01:57:07 d2.utils.events]:  eta: 4:47:57  iter: 79  total_loss: 0.2532  loss_cls: 0.2088  loss_box_reg: 0.03865  loss_rpn_cls: 0.006046  loss_rpn_loc: 0.002246  time: 18.5259  data_time: 0.0020  lr: 1.998e-05  
[04/18 02:02:59 d2.utils.events]:  eta: 4:39:46  iter: 99  total_loss: 0.1582  loss_cls: 0.1109  loss_box_reg: 0.03531  loss_rpn_cls: 0.004905  loss_rpn_loc: 0.00194  time: 18.3324  data_time: 0.0020  lr: 2.4975e-05  
[04/18 02:09:05 d2.utils.events]:  eta: 4:32:11  iter: 119  total_loss: 0.1132  loss_cls: 0.07876  loss_box_reg: 0.029  loss_rpn_cls: 0.006646  loss_rpn_loc: 0.001567  time: 18.3254  data_time: 0.0020  lr: 2.997e-05  
[04/18 02:15:07 d2.utils.events]:  eta: 4:25:15  iter: 139  total_loss: 0.09183  loss_cls: 0.05819  loss_box_reg: 0.02747  loss_rpn_cls: 0.003081  loss_rpn_loc: 0.001677  time: 18.2951  data_time: 0.0021  lr: 3.4965e-05  
[04/18 02:21:16 d2.utils.events]:  eta: 4:19:31  iter: 159  total_loss: 0.08022  loss_cls: 0.05056  loss_box_reg: 0.02352  loss_rpn_cls: 0.002945  loss_rpn_loc: 0.001465  time: 18.3150  data_time: 0.0020  lr: 3.996e-05  
[04/18 02:27:18 d2.utils.events]:  eta: 4:13:21  iter: 179  total_loss: 0.0704  loss_cls: 0.04052  loss_box_reg: 0.02233  loss_rpn_cls: 0.003622  loss_rpn_loc: 0.00137  time: 18.2924  data_time: 0.0020  lr: 4.4955e-05  
[04/18 02:33:13 d2.utils.events]:  eta: 4:06:45  iter: 199  total_loss: 0.06643  loss_cls: 0.03568  loss_box_reg: 0.02204  loss_rpn_cls: 0.001912  loss_rpn_loc: 0.001437  time: 18.2375  data_time: 0.0019  lr: 4.995e-05  
[04/18 02:39:22 d2.utils.events]:  eta: 4:01:18  iter: 219  total_loss: 0.05395  loss_cls: 0.02873  loss_box_reg: 0.01957  loss_rpn_cls: 0.001142  loss_rpn_loc: 0.001433  time: 18.2540  data_time: 0.0019  lr: 5.4945e-05  
[04/18 02:45:20 d2.utils.events]:  eta: 3:54:59  iter: 239  total_loss: 0.05068  loss_cls: 0.02406  loss_box_reg: 0.01945  loss_rpn_cls: 0.001917  loss_rpn_loc: 0.00169  time: 18.2263  data_time: 0.0019  lr: 5.994e-05  
[04/18 02:51:22 d2.utils.events]:  eta: 3:48:38  iter: 259  total_loss: 0.04721  loss_cls: 0.02217  loss_box_reg: 0.01809  loss_rpn_cls: 0.0005249  loss_rpn_loc: 0.001457  time: 18.2164  data_time: 0.0020  lr: 6.4935e-05  
[04/18 02:57:15 d2.utils.events]:  eta: 3:41:53  iter: 279  total_loss: 0.04237  loss_cls: 0.0209  loss_box_reg: 0.01618  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.001333  time: 18.1742  data_time: 0.0020  lr: 6.993e-05  
[04/18 03:03:06 d2.utils.events]:  eta: 3:35:32  iter: 299  total_loss: 0.03925  loss_cls: 0.0171  loss_box_reg: 0.01769  loss_rpn_cls: 0.0007261  loss_rpn_loc: 0.00165  time: 18.1311  data_time: 0.0020  lr: 7.4925e-05  
[04/18 03:08:55 d2.utils.events]:  eta: 3:29:00  iter: 319  total_loss: 0.03618  loss_cls: 0.01579  loss_box_reg: 0.01592  loss_rpn_cls: 0.001036  loss_rpn_loc: 0.001347  time: 18.0908  data_time: 0.0021  lr: 7.992e-05  
[04/18 03:14:57 d2.utils.events]:  eta: 3:22:51  iter: 339  total_loss: 0.03613  loss_cls: 0.0158  loss_box_reg: 0.0156  loss_rpn_cls: 0.0003653  loss_rpn_loc: 0.001151  time: 18.0898  data_time: 0.0020  lr: 8.4915e-05  
[04/18 03:20:50 d2.utils.events]:  eta: 3:16:30  iter: 359  total_loss: 0.03383  loss_cls: 0.01312  loss_box_reg: 0.01543  loss_rpn_cls: 0.0008376  loss_rpn_loc: 0.001409  time: 18.0640  data_time: 0.0021  lr: 8.991e-05  
[04/18 03:26:54 d2.utils.events]:  eta: 3:10:24  iter: 379  total_loss: 0.03099  loss_cls: 0.01355  loss_box_reg: 0.01502  loss_rpn_cls: 0.0005183  loss_rpn_loc: 0.001388  time: 18.0718  data_time: 0.0020  lr: 9.4905e-05  
[04/18 03:32:54 d2.utils.events]:  eta: 3:04:16  iter: 399  total_loss: 0.03039  loss_cls: 0.01344  loss_box_reg: 0.01443  loss_rpn_cls: 0.000277  loss_rpn_loc: 0.001423  time: 18.0673  data_time: 0.0021  lr: 9.99e-05  
[04/18 03:38:52 d2.utils.events]:  eta: 2:58:07  iter: 419  total_loss: 0.02967  loss_cls: 0.01228  loss_box_reg: 0.01465  loss_rpn_cls: 0.000542  loss_rpn_loc: 0.001186  time: 18.0598  data_time: 0.0020  lr: 0.0001049  
[04/18 03:44:46 d2.utils.events]:  eta: 2:51:47  iter: 439  total_loss: 0.031  loss_cls: 0.01304  loss_box_reg: 0.01436  loss_rpn_cls: 0.0004862  loss_rpn_loc: 0.0014  time: 18.0428  data_time: 0.0019  lr: 0.00010989  
[04/18 03:50:33 d2.utils.events]:  eta: 2:45:24  iter: 459  total_loss: 0.03131  loss_cls: 0.01381  loss_box_reg: 0.01447  loss_rpn_cls: 0.0004362  loss_rpn_loc: 0.001156  time: 18.0145  data_time: 0.0018  lr: 0.00011489  
[04/18 03:56:09 d2.utils.events]:  eta: 2:38:39  iter: 479  total_loss: 0.02718  loss_cls: 0.01136  loss_box_reg: 0.01398  loss_rpn_cls: 0.0005622  loss_rpn_loc: 0.001155  time: 17.9609  data_time: 0.0020  lr: 0.00011988  
[04/18 04:01:57 d2.utils.events]:  eta: 2:32:27  iter: 499  total_loss: 0.02569  loss_cls: 0.01187  loss_box_reg: 0.01248  loss_rpn_cls: 0.0003412  loss_rpn_loc: 0.001091  time: 17.9393  data_time: 0.0021  lr: 0.00012488  
[04/18 04:07:51 d2.utils.events]:  eta: 2:26:07  iter: 519  total_loss: 0.02326  loss_cls: 0.009654  loss_box_reg: 0.01271  loss_rpn_cls: 0.0003964  loss_rpn_loc: 0.001237  time: 17.9294  data_time: 0.0019  lr: 0.00012987  
[04/18 04:13:40 d2.utils.events]:  eta: 2:19:41  iter: 539  total_loss: 0.02579  loss_cls: 0.01066  loss_box_reg: 0.01332  loss_rpn_cls: 0.0002274  loss_rpn_loc: 0.001478  time: 17.9120  data_time: 0.0019  lr: 0.00013487  
[04/18 04:19:40 d2.utils.events]:  eta: 2:13:42  iter: 559  total_loss: 0.02634  loss_cls: 0.01044  loss_box_reg: 0.01238  loss_rpn_cls: 0.0002419  loss_rpn_loc: 0.001482  time: 17.9145  data_time: 0.0019  lr: 0.00013986  
[04/18 04:25:19 d2.utils.events]:  eta: 2:07:22  iter: 579  total_loss: 0.02438  loss_cls: 0.00931  loss_box_reg: 0.01301  loss_rpn_cls: 0.0006606  loss_rpn_loc: 0.001174  time: 17.8815  data_time: 0.0020  lr: 0.00014486  
[04/18 04:31:10 d2.utils.events]:  eta: 2:01:19  iter: 599  total_loss: 0.0255  loss_cls: 0.00938  loss_box_reg: 0.01151  loss_rpn_cls: 0.000204  loss_rpn_loc: 0.001024  time: 17.8701  data_time: 0.0019  lr: 0.00014985  
[04/18 04:37:16 d2.utils.events]:  eta: 1:55:14  iter: 619  total_loss: 0.02421  loss_cls: 0.009923  loss_box_reg: 0.01264  loss_rpn_cls: 0.0001592  loss_rpn_loc: 0.0009695  time: 17.8835  data_time: 0.0020  lr: 0.00015485  
[04/18 04:42:54 d2.utils.events]:  eta: 1:49:09  iter: 639  total_loss: 0.02539  loss_cls: 0.01008  loss_box_reg: 0.01287  loss_rpn_cls: 0.0002745  loss_rpn_loc: 0.0009876  time: 17.8530  data_time: 0.0021  lr: 0.00015984  
[04/18 04:48:34 d2.utils.events]:  eta: 1:42:57  iter: 659  total_loss: 0.02572  loss_cls: 0.009635  loss_box_reg: 0.01197  loss_rpn_cls: 0.0003253  loss_rpn_loc: 0.001214  time: 17.8271  data_time: 0.0019  lr: 0.00016484  
[04/18 04:54:16 d2.utils.events]:  eta: 1:36:49  iter: 679  total_loss: 0.0241  loss_cls: 0.009519  loss_box_reg: 0.01222  loss_rpn_cls: 0.0001234  loss_rpn_loc: 0.001038  time: 17.8061  data_time: 0.0020  lr: 0.00016983  
[04/18 05:00:00 d2.utils.events]:  eta: 1:30:45  iter: 699  total_loss: 0.0229  loss_cls: 0.009676  loss_box_reg: 0.01236  loss_rpn_cls: 0.0001098  loss_rpn_loc: 0.0009571  time: 17.7886  data_time: 0.0020  lr: 0.00017483  
[04/18 05:05:45 d2.utils.events]:  eta: 1:24:35  iter: 719  total_loss: 0.02126  loss_cls: 0.007903  loss_box_reg: 0.01143  loss_rpn_cls: 9.884e-05  loss_rpn_loc: 0.0008392  time: 17.7729  data_time: 0.0021  lr: 0.00017982  
[04/18 05:11:33 d2.utils.events]:  eta: 1:18:25  iter: 739  total_loss: 0.02188  loss_cls: 0.00784  loss_box_reg: 0.01216  loss_rpn_cls: 0.0001374  loss_rpn_loc: 0.0009  time: 17.7636  data_time: 0.0021  lr: 0.00018482  
[04/18 05:17:27 d2.utils.events]:  eta: 1:12:25  iter: 759  total_loss: 0.02071  loss_cls: 0.00835  loss_box_reg: 0.01175  loss_rpn_cls: 9.766e-05  loss_rpn_loc: 0.001034  time: 17.7608  data_time: 0.0021  lr: 0.00018981  
[04/18 05:23:21 d2.utils.events]:  eta: 1:06:27  iter: 779  total_loss: 0.02226  loss_cls: 0.009327  loss_box_reg: 0.01173  loss_rpn_cls: 0.0001086  loss_rpn_loc: 0.0009251  time: 17.7596  data_time: 0.0019  lr: 0.00019481  
[04/18 05:29:18 d2.utils.events]:  eta: 1:00:26  iter: 799  total_loss: 0.02091  loss_cls: 0.008696  loss_box_reg: 0.01086  loss_rpn_cls: 6.545e-05  loss_rpn_loc: 0.001047  time: 17.7616  data_time: 0.0020  lr: 0.0001998  
[04/18 05:35:24 d2.utils.events]:  eta: 0:54:30  iter: 819  total_loss: 0.02111  loss_cls: 0.009786  loss_box_reg: 0.01013  loss_rpn_cls: 0.0001398  loss_rpn_loc: 0.0009854  time: 17.7751  data_time: 0.0021  lr: 0.0002048  
[04/18 05:41:21 d2.utils.events]:  eta: 0:48:25  iter: 839  total_loss: 0.02055  loss_cls: 0.008223  loss_box_reg: 0.01076  loss_rpn_cls: 0.0001488  loss_rpn_loc: 0.0008822  time: 17.7765  data_time: 0.0021  lr: 0.00020979  
[04/18 05:47:08 d2.utils.events]:  eta: 0:42:21  iter: 859  total_loss: 0.02377  loss_cls: 0.009216  loss_box_reg: 0.01161  loss_rpn_cls: 0.0001456  loss_rpn_loc: 0.0009631  time: 17.7663  data_time: 0.0021  lr: 0.00021479  
[04/18 05:52:49 d2.utils.events]:  eta: 0:36:18  iter: 879  total_loss: 0.02197  loss_cls: 0.008317  loss_box_reg: 0.0115  loss_rpn_cls: 0.000122  loss_rpn_loc: 0.001208  time: 17.7507  data_time: 0.0020  lr: 0.00021978  
[04/18 05:58:41 d2.utils.events]:  eta: 0:30:14  iter: 899  total_loss: 0.02103  loss_cls: 0.007927  loss_box_reg: 0.01078  loss_rpn_cls: 8.025e-05  loss_rpn_loc: 0.00104  time: 17.7470  data_time: 0.0020  lr: 0.00022478  
[04/18 06:04:44 d2.utils.events]:  eta: 0:24:12  iter: 919  total_loss: 0.02079  loss_cls: 0.009006  loss_box_reg: 0.01048  loss_rpn_cls: 4.533e-05  loss_rpn_loc: 0.0007968  time: 17.7551  data_time: 0.0021  lr: 0.00022977  
[04/18 06:10:46 d2.utils.events]:  eta: 0:18:09  iter: 939  total_loss: 0.01944  loss_cls: 0.008402  loss_box_reg: 0.009422  loss_rpn_cls: 7.19e-05  loss_rpn_loc: 0.0008317  time: 17.7623  data_time: 0.0021  lr: 0.00023477  
[04/18 06:16:28 d2.utils.events]:  eta: 0:12:05  iter: 959  total_loss: 0.01951  loss_cls: 0.008037  loss_box_reg: 0.0103  loss_rpn_cls: 6.358e-05  loss_rpn_loc: 0.001158  time: 17.7486  data_time: 0.0020  lr: 0.00023976  
[04/18 06:22:34 d2.utils.events]:  eta: 0:06:03  iter: 979  total_loss: 0.01953  loss_cls: 0.007606  loss_box_reg: 0.011  loss_rpn_cls: 6.104e-05  loss_rpn_loc: 0.0009221  time: 17.7599  data_time: 0.0019  lr: 0.00024476  
[04/18 06:28:33 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.02  loss_cls: 0.008442  loss_box_reg: 0.01034  loss_rpn_cls: 0.0001204  loss_rpn_loc: 0.001258  time: 17.7630  data_time: 0.0019  lr: 0.00024975  
[04/18 06:28:33 d2.engine.hooks]: Overall training speed: 998 iterations in 4:55:27 (17.7631 s / it)
[04/18 06:28:33 d2.engine.hooks]: Total training time: 4:55:31 (0:00:03 on hooks)
WARNING [04/18 06:28:33 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[04/18 06:28:33 d2.data.datasets.coco]: Loaded 5 images in COCO format from test.json
[04/18 06:28:33 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    kiwi    | 5            |
|            |              |
[04/18 06:28:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[04/18 06:28:33 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...
[04/18 06:28:33 d2.data.common]: Serialized dataset takes 0.00 MiB
WARNING [04/18 06:28:33 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.

Process finished with exit code 0
