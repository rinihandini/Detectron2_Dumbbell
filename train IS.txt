C:\Users\user\anaconda3\python.exe D:/Detectron2_Custom_Dataset/train.py
[04/18 14:46:39 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
WARNING [04/18 14:46:39 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[04/18 14:46:39 d2.data.datasets.coco]: Loaded 20 images in COCO format from train.json
[04/18 14:46:39 d2.data.build]: Removed 0 images with no usable annotations. 20 images left.
[04/18 14:46:39 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    kiwi    | 25           |
|            |              |
[04/18 14:46:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[04/18 14:46:39 d2.data.build]: Using training sampler TrainingSampler
[04/18 14:46:39 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...
[04/18 14:46:39 d2.data.common]: Serialized dataset takes 0.02 MiB
model_final_f10217.pkl: 178MB [00:17, 10.1MB/s]                           
[04/18 14:46:58 d2.engine.train_loop]: Starting training from iteration 0
C:\Users\user\anaconda3\lib\site-packages\torch\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[04/18 14:57:40 d2.utils.events]:  eta: 8:19:58  iter: 19  total_loss: 0.704  loss_cls: 0.4394  loss_box_reg: 0.04866  loss_mask: 0.1344  loss_rpn_cls: 0.004107  loss_rpn_loc: 0.002494  time: 30.8210  data_time: 0.4206  lr: 4.9953e-06  
[04/18 15:07:17 d2.utils.events]:  eta: 7:30:08  iter: 39  total_loss: 0.5623  loss_cls: 0.432  loss_box_reg: 0.04455  loss_mask: 0.07592  loss_rpn_cls: 0.00355  loss_rpn_loc: 0.002601  time: 29.7643  data_time: 0.0035  lr: 9.9902e-06  
[04/18 15:19:08 d2.utils.events]:  eta: 8:15:21  iter: 59  total_loss: 0.4456  loss_cls: 0.3077  loss_box_reg: 0.03687  loss_mask: 0.04844  loss_rpn_cls: 0.001532  loss_rpn_loc: 0.002174  time: 31.7622  data_time: 0.0044  lr: 1.4985e-05  
[04/18 15:30:43 d2.utils.events]:  eta: 8:13:46  iter: 79  total_loss: 0.2594  loss_cls: 0.1563  loss_box_reg: 0.03025  loss_mask: 0.04168  loss_rpn_cls: 0.004597  loss_rpn_loc: 0.001846  time: 32.5240  data_time: 0.0036  lr: 1.998e-05  
[04/18 15:41:48 d2.utils.events]:  eta: 8:05:42  iter: 99  total_loss: 0.1639  loss_cls: 0.09463  loss_box_reg: 0.02341  loss_mask: 0.03833  loss_rpn_cls: 0.002561  loss_rpn_loc: 0.002239  time: 32.6781  data_time: 0.0085  lr: 2.4975e-05  
[04/18 15:51:36 d2.utils.events]:  eta: 7:43:44  iter: 119  total_loss: 0.1297  loss_cls: 0.06487  loss_box_reg: 0.02297  loss_mask: 0.03547  loss_rpn_cls: 0.003552  loss_rpn_loc: 0.001203  time: 32.1188  data_time: 0.0037  lr: 2.997e-05  
[04/18 16:02:42 d2.utils.events]:  eta: 7:37:19  iter: 139  total_loss: 0.1088  loss_cls: 0.05423  loss_box_reg: 0.01924  loss_mask: 0.03355  loss_rpn_cls: 0.003337  loss_rpn_loc: 0.001254  time: 32.2922  data_time: 0.0046  lr: 3.4965e-05  
[04/18 16:12:57 d2.utils.events]:  eta: 7:25:28  iter: 159  total_loss: 0.09852  loss_cls: 0.04761  loss_box_reg: 0.01818  loss_mask: 0.03169  loss_rpn_cls: 0.001637  loss_rpn_loc: 0.001381  time: 32.0904  data_time: 0.0041  lr: 3.996e-05  
[04/18 16:22:19 d2.utils.events]:  eta: 7:05:04  iter: 179  total_loss: 0.08609  loss_cls: 0.03547  loss_box_reg: 0.0169  loss_mask: 0.03119  loss_rpn_cls: 0.003635  loss_rpn_loc: 0.001488  time: 31.6428  data_time: 0.0027  lr: 4.4955e-05  
[04/18 16:30:28 d2.utils.events]:  eta: 6:47:55  iter: 199  total_loss: 0.0872  loss_cls: 0.03195  loss_box_reg: 0.01755  loss_mask: 0.03054  loss_rpn_cls: 0.002329  loss_rpn_loc: 0.001209  time: 30.9152  data_time: 0.0041  lr: 4.995e-05  
[04/18 16:38:58 d2.utils.events]:  eta: 6:29:14  iter: 219  total_loss: 0.07868  loss_cls: 0.02708  loss_box_reg: 0.01662  loss_mask: 0.03045  loss_rpn_cls: 0.001845  loss_rpn_loc: 0.001574  time: 30.4213  data_time: 0.0026  lr: 5.4945e-05  
[04/18 16:48:16 d2.utils.events]:  eta: 6:13:54  iter: 239  total_loss: 0.07207  loss_cls: 0.02178  loss_box_reg: 0.01463  loss_mask: 0.03001  loss_rpn_cls: 0.001817  loss_rpn_loc: 0.001291  time: 30.2089  data_time: 0.0031  lr: 5.994e-05  
[04/18 16:57:52 d2.utils.events]:  eta: 6:02:20  iter: 259  total_loss: 0.07017  loss_cls: 0.02209  loss_box_reg: 0.01505  loss_mask: 0.02854  loss_rpn_cls: 0.0005835  loss_rpn_loc: 0.001117  time: 30.0997  data_time: 0.0033  lr: 6.4935e-05  
[04/18 17:07:15 d2.utils.events]:  eta: 5:51:44  iter: 279  total_loss: 0.06784  loss_cls: 0.01822  loss_box_reg: 0.01512  loss_mask: 0.02794  loss_rpn_cls: 0.001189  loss_rpn_loc: 0.001427  time: 29.9594  data_time: 0.0045  lr: 6.993e-05  
[04/18 17:14:44 d2.utils.events]:  eta: 5:38:44  iter: 299  total_loss: 0.06721  loss_cls: 0.01767  loss_box_reg: 0.01426  loss_mask: 0.02889  loss_rpn_cls: 0.002068  loss_rpn_loc: 0.001139  time: 29.4540  data_time: 0.0028  lr: 7.4925e-05  
[04/18 17:23:42 d2.utils.events]:  eta: 5:25:32  iter: 319  total_loss: 0.06285  loss_cls: 0.01522  loss_box_reg: 0.01528  loss_mask: 0.02777  loss_rpn_cls: 0.0005303  loss_rpn_loc: 0.001384  time: 29.2946  data_time: 0.0038  lr: 7.992e-05  
[04/18 17:32:25 d2.utils.events]:  eta: 5:12:45  iter: 339  total_loss: 0.06252  loss_cls: 0.01403  loss_box_reg: 0.0143  loss_mask: 0.02818  loss_rpn_cls: 0.0011  loss_rpn_loc: 0.000977  time: 29.1084  data_time: 0.0033  lr: 8.4915e-05  
[04/18 17:40:57 d2.utils.events]:  eta: 5:01:16  iter: 359  total_loss: 0.05911  loss_cls: 0.01273  loss_box_reg: 0.01524  loss_mask: 0.02731  loss_rpn_cls: 0.0005814  loss_rpn_loc: 0.00119  time: 28.9105  data_time: 0.0029  lr: 8.991e-05  
[04/18 17:48:02 d2.utils.events]:  eta: 4:49:55  iter: 379  total_loss: 0.05731  loss_cls: 0.01298  loss_box_reg: 0.01355  loss_mask: 0.02652  loss_rpn_cls: 0.0006495  loss_rpn_loc: 0.00118  time: 28.5066  data_time: 0.0028  lr: 9.4905e-05  
[04/18 17:55:21 d2.utils.events]:  eta: 4:36:04  iter: 399  total_loss: 0.05485  loss_cls: 0.01193  loss_box_reg: 0.0133  loss_mask: 0.02757  loss_rpn_cls: 0.0004834  loss_rpn_loc: 0.0009714  time: 28.1758  data_time: 0.0027  lr: 9.99e-05  
[04/18 18:02:34 d2.utils.events]:  eta: 4:22:27  iter: 419  total_loss: 0.05556  loss_cls: 0.01324  loss_box_reg: 0.01255  loss_mask: 0.02578  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.0009268  time: 27.8648  data_time: 0.0024  lr: 0.0001049  
[04/18 18:09:44 d2.utils.events]:  eta: 4:10:50  iter: 439  total_loss: 0.05316  loss_cls: 0.01194  loss_box_reg: 0.01118  loss_mask: 0.02585  loss_rpn_cls: 0.000815  loss_rpn_loc: 0.001132  time: 27.5728  data_time: 0.0026  lr: 0.00010989  
[04/18 18:17:06 d2.utils.events]:  eta: 3:59:04  iter: 459  total_loss: 0.04902  loss_cls: 0.01012  loss_box_reg: 0.01207  loss_mask: 0.02492  loss_rpn_cls: 0.0003007  loss_rpn_loc: 0.001117  time: 27.3342  data_time: 0.0029  lr: 0.00011489  
[04/18 18:24:31 d2.utils.events]:  eta: 3:45:45  iter: 479  total_loss: 0.0527  loss_cls: 0.01071  loss_box_reg: 0.0119  loss_mask: 0.02509  loss_rpn_cls: 0.0004652  loss_rpn_loc: 0.001215  time: 27.1202  data_time: 0.0024  lr: 0.00011988  
[04/18 18:31:56 d2.utils.events]:  eta: 3:34:20  iter: 499  total_loss: 0.04922  loss_cls: 0.008275  loss_box_reg: 0.01206  loss_mask: 0.02424  loss_rpn_cls: 0.0005462  loss_rpn_loc: 0.000978  time: 26.9252  data_time: 0.0027  lr: 0.00012488  
[04/18 18:39:31 d2.utils.events]:  eta: 3:22:49  iter: 519  total_loss: 0.0501  loss_cls: 0.01129  loss_box_reg: 0.01212  loss_mask: 0.02373  loss_rpn_cls: 0.0003112  loss_rpn_loc: 0.001211  time: 26.7643  data_time: 0.0026  lr: 0.00012987  
[04/18 18:46:36 d2.utils.events]:  eta: 3:13:07  iter: 539  total_loss: 0.04872  loss_cls: 0.009981  loss_box_reg: 0.01281  loss_mask: 0.02421  loss_rpn_cls: 0.0009164  loss_rpn_loc: 0.0009541  time: 26.5598  data_time: 0.0026  lr: 0.00013487  
[04/18 18:53:58 d2.utils.events]:  eta: 3:02:36  iter: 559  total_loss: 0.04722  loss_cls: 0.009333  loss_box_reg: 0.01137  loss_mask: 0.02373  loss_rpn_cls: 0.0002965  loss_rpn_loc: 0.001112  time: 26.3988  data_time: 0.0024  lr: 0.00013986  
[04/18 19:01:11 d2.utils.events]:  eta: 2:51:16  iter: 579  total_loss: 0.04945  loss_cls: 0.01075  loss_box_reg: 0.0105  loss_mask: 0.02376  loss_rpn_cls: 0.0002215  loss_rpn_loc: 0.001008  time: 26.2343  data_time: 0.0026  lr: 0.00014486  
[04/18 19:08:34 d2.utils.events]:  eta: 2:42:17  iter: 599  total_loss: 0.04674  loss_cls: 0.009127  loss_box_reg: 0.01113  loss_mask: 0.02318  loss_rpn_cls: 0.0001802  loss_rpn_loc: 0.001238  time: 26.0973  data_time: 0.0025  lr: 0.00014985  
[04/18 19:15:57 d2.utils.events]:  eta: 2:32:53  iter: 619  total_loss: 0.04445  loss_cls: 0.009539  loss_box_reg: 0.01119  loss_mask: 0.0232  loss_rpn_cls: 0.0001317  loss_rpn_loc: 0.0008964  time: 25.9697  data_time: 0.0026  lr: 0.00015485  
[04/18 19:23:15 d2.utils.events]:  eta: 2:24:25  iter: 639  total_loss: 0.04843  loss_cls: 0.0105  loss_box_reg: 0.01261  loss_mask: 0.02245  loss_rpn_cls: 0.0004729  loss_rpn_loc: 0.001142  time: 25.8421  data_time: 0.0028  lr: 0.00015984  
[04/18 19:30:35 d2.utils.events]:  eta: 2:15:43  iter: 659  total_loss: 0.04566  loss_cls: 0.01007  loss_box_reg: 0.01176  loss_mask: 0.02163  loss_rpn_cls: 0.0001788  loss_rpn_loc: 0.0009959  time: 25.7247  data_time: 0.0027  lr: 0.00016484  
[04/18 19:37:51 d2.utils.events]:  eta: 2:07:25  iter: 679  total_loss: 0.04503  loss_cls: 0.009288  loss_box_reg: 0.01152  loss_mask: 0.02207  loss_rpn_cls: 0.0001652  loss_rpn_loc: 0.001044  time: 25.6091  data_time: 0.0024  lr: 0.00016983  
[04/18 19:45:16 d2.utils.events]:  eta: 1:59:17  iter: 699  total_loss: 0.04552  loss_cls: 0.009517  loss_box_reg: 0.01149  loss_mask: 0.02207  loss_rpn_cls: 0.0001682  loss_rpn_loc: 0.001075  time: 25.5132  data_time: 0.0026  lr: 0.00017483  
[04/18 19:52:30 d2.utils.events]:  eta: 1:51:02  iter: 719  total_loss: 0.04135  loss_cls: 0.007195  loss_box_reg: 0.01048  loss_mask: 0.02168  loss_rpn_cls: 0.0001025  loss_rpn_loc: 0.0008852  time: 25.4074  data_time: 0.0026  lr: 0.00017982  
[04/18 19:59:46 d2.utils.events]:  eta: 1:42:49  iter: 739  total_loss: 0.04233  loss_cls: 0.008927  loss_box_reg: 0.01011  loss_mask: 0.02135  loss_rpn_cls: 0.0001825  loss_rpn_loc: 0.0008055  time: 25.3093  data_time: 0.0025  lr: 0.00018482  
[04/18 20:07:06 d2.utils.events]:  eta: 1:34:46  iter: 759  total_loss: 0.04536  loss_cls: 0.01029  loss_box_reg: 0.01179  loss_mask: 0.02164  loss_rpn_cls: 0.0002367  loss_rpn_loc: 0.0008205  time: 25.2223  data_time: 0.0025  lr: 0.00018981  
[04/18 20:14:26 d2.utils.events]:  eta: 1:26:40  iter: 779  total_loss: 0.04428  loss_cls: 0.009303  loss_box_reg: 0.01097  loss_mask: 0.02116  loss_rpn_cls: 0.0001606  loss_rpn_loc: 0.0008369  time: 25.1395  data_time: 0.0028  lr: 0.00019481  
[04/18 20:21:48 d2.utils.events]:  eta: 1:18:46  iter: 799  total_loss: 0.04202  loss_cls: 0.008453  loss_box_reg: 0.01053  loss_mask: 0.02068  loss_rpn_cls: 0.0001788  loss_rpn_loc: 0.001058  time: 25.0621  data_time: 0.0026  lr: 0.0001998  
[04/18 20:28:56 d2.utils.events]:  eta: 1:10:45  iter: 819  total_loss: 0.04149  loss_cls: 0.008358  loss_box_reg: 0.01037  loss_mask: 0.0204  loss_rpn_cls: 0.0001028  loss_rpn_loc: 0.0008531  time: 24.9730  data_time: 0.0027  lr: 0.0002048  
[04/18 20:36:04 d2.utils.events]:  eta: 1:02:46  iter: 839  total_loss: 0.04154  loss_cls: 0.008073  loss_box_reg: 0.01085  loss_mask: 0.02039  loss_rpn_cls: 0.0001197  loss_rpn_loc: 0.0009489  time: 24.8882  data_time: 0.0029  lr: 0.00020979  
[04/18 20:43:16 d2.utils.events]:  eta: 0:54:49  iter: 859  total_loss: 0.04161  loss_cls: 0.008341  loss_box_reg: 0.01014  loss_mask: 0.02042  loss_rpn_cls: 0.0001218  loss_rpn_loc: 0.0009945  time: 24.8113  data_time: 0.0026  lr: 0.00021479  
[04/18 20:50:51 d2.utils.events]:  eta: 0:46:59  iter: 879  total_loss: 0.03833  loss_cls: 0.007043  loss_box_reg: 0.01007  loss_mask: 0.02032  loss_rpn_cls: 0.0002502  loss_rpn_loc: 0.001004  time: 24.7645  data_time: 0.0031  lr: 0.00021978  
[04/18 20:58:06 d2.utils.events]:  eta: 0:39:08  iter: 899  total_loss: 0.03923  loss_cls: 0.00758  loss_box_reg: 0.01038  loss_mask: 0.02  loss_rpn_cls: 0.0002058  loss_rpn_loc: 0.0009304  time: 24.6965  data_time: 0.0028  lr: 0.00022478  
[04/18 21:05:26 d2.utils.events]:  eta: 0:31:16  iter: 919  total_loss: 0.03938  loss_cls: 0.007575  loss_box_reg: 0.00932  loss_mask: 0.01979  loss_rpn_cls: 9.929e-05  loss_rpn_loc: 0.001023  time: 24.6381  data_time: 0.0026  lr: 0.00022977  
[04/18 21:12:59 d2.utils.events]:  eta: 0:23:25  iter: 939  total_loss: 0.03812  loss_cls: 0.009351  loss_box_reg: 0.009419  loss_mask: 0.01914  loss_rpn_cls: 0.0001011  loss_rpn_loc: 0.001056  time: 24.5960  data_time: 0.0027  lr: 0.00023477  
[04/18 21:20:16 d2.utils.events]:  eta: 0:15:36  iter: 959  total_loss: 0.03847  loss_cls: 0.00713  loss_box_reg: 0.009621  loss_mask: 0.01991  loss_rpn_cls: 0.0001453  loss_rpn_loc: 0.0009273  time: 24.5381  data_time: 0.0027  lr: 0.00023976  
[04/18 21:27:42 d2.utils.events]:  eta: 0:07:47  iter: 979  total_loss: 0.03912  loss_cls: 0.008355  loss_box_reg: 0.009751  loss_mask: 0.01954  loss_rpn_cls: 0.0001616  loss_rpn_loc: 0.001043  time: 24.4927  data_time: 0.0028  lr: 0.00024476  
[04/18 21:35:05 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.03958  loss_cls: 0.008709  loss_box_reg: 0.01041  loss_mask: 0.0194  loss_rpn_cls: 0.0001283  loss_rpn_loc: 0.00106  time: 24.4436  data_time: 0.0029  lr: 0.00024975  
[04/18 21:35:05 d2.engine.hooks]: Overall training speed: 998 iterations in 6:46:34 (24.4436 s / it)
[04/18 21:35:05 d2.engine.hooks]: Total training time: 6:46:39 (0:00:04 on hooks)
WARNING [04/18 21:35:05 d2.data.datasets.coco]: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[04/18 21:35:05 d2.data.datasets.coco]: Loaded 5 images in COCO format from test.json
[04/18 21:35:05 d2.data.build]: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    kiwi    | 5            |
|            |              |
[04/18 21:35:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[04/18 21:35:05 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...
[04/18 21:35:05 d2.data.common]: Serialized dataset takes 0.00 MiB
WARNING [04/18 21:35:05 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.

Process finished with exit code 0
